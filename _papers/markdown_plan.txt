*step one: Baseline*:
- 1. Dataset for project: Sentiment Analysis 140
   *(Twitter messages divided in 3 categories (positive, negative, neutral)dataset developed by Stanford University Students during NLP Lectures)*

- 2. Pre-processing of data
    - spelling correction *(basic method but better than nothing. pattern.en API will provide an easy way to clean data. word will be corrected if the result is > 0.9)*
    - heldout dataset: dataset is big enough (1.6 Millions Training documents + 500 Test)=> split in 1,28M Docs for Training, 0.32M docs for Test, 500 docs for Dev
- 3. Implement baseline classifier: MaxEnt (LogisticRegression) Classifier with Unigram, TD*IDF with pre-processed data
    *(we will use scikit: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html, 
    https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html
    Why TD*IDF? in "Word clustering based on POS feature for efficient twitter sentiment analysis" introduction => described as one of the most robust and efficient schemes for feature weighing.
    )*
    
*step two: PoS Tagging*:
- 1. The most promising POS Tagger for Twitter is the GATE Twitter part-of-speech tagger.
	*(see "Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data" conclusion, all results in this paper helped to build it. 
		it improved upon the good work already done by the Stanford POS Tagger)*
	*This tagger will provide some special handling of slang, which is really helpful for Twitter*
- 2. Other data processing step needed => create an input file with one tweet per line.
	The Tagger will output the result in another file. The new file will need another parsing step to get the POS.


*step three: Weighing Schemes (big one)*:
- 1. Previous Related Work: summarise what has been done in papers
(-> *_let's already start a MarkDown note with bullet points: most important points from papers we read_*)
- 2. choose which weighing schemes to implement
- 3. try out/implement weighing schemes
- 4. record results in a table for easy comparison

*step four: Discussion*:
- 1. describe results
- 2. discuss what results mean, compare weighing schemes
- 3. compare with papers from Related Work section

*step five: Other Classifiers*
- 1. implement the tagging techniques with other classifiers
- 2. Discuss/compare

*Weighting Schemes: Improving Sentiment Analysis with Part-Of-Speech Weighting*
1. How to weigh PoS?
- The paper specify a strength for each PoS. Here 4 classes of PoS is used (noun, verb, adjective, verb) with each strength ranging from 1-5. Then the feature weight is normalized over all PoS strengths in the document
2. How to assign initial strength?
- As there are 4 classes, there are 625 possible combinations (5^4). Here we can try for every possible combination, and use OCFS to reduce our feature. The paper also include Improved Iterative Scaling to fine tune the results, but I think this can be optional for us, as we aim to investigate different PoS weighing scheme. Based on the feature that passed our OCFS filter and result on testdata, we can discuss which PoS plays an important role to capture the sentiment.
3. How to use OCFS to reduce the number of features: See Chapter "4.3 An Illustrating Example". @TODO: how do we define how many features do we want to keep?

*A POS-based Ensemble Model for Cross-domain Sentiment Classification*
1.  This paper concentrates on Transfer Learning using POS Tag Groups for sentiment classification. While the cross domain part of this paper is not so interesting in itself, the grouping problematic is interesting for our project(which POS are signigficant for classification in a general way? how to group them?)
2. Proposed grouping: J for [adjectives, adverbs] V for [verbs],  N for [nouns], [O the other POS tags]
3. In the paper, each group is a feature, weights are learned with gradient descend based on 2 models: Perceptron and Minimal Classification error.
=> RL: I suggest ever to learn the weights as any normal feature in the MaxEnt. Or we could simply use this Grouping and mix the methodology used in *Weighting Schemes: Improving Sentiment Analysis with Part-Of-Speech Weighting*

*Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data*
1. This paper points to the best POS Tagger for twitter ( slang handling for example). RL: What I am not sure of => if we need to perform spelling correction before or if the Tagger will be to do that on the fly to assign the right POS